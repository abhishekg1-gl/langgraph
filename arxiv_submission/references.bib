@inproceedings{brown2020language,
  author = {T. Brown and others},
  title = {Language Models are Few-Shot Learners},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {1877--1901},
  year = {2020}
}

@article{ji2023survey,
  author = {Z. Ji and others},
  title = {Survey of Hallucination in Natural Language Generation},
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {12},
  pages = {1--38},
  year = {2023}
}

@inproceedings{lewis2020retrieval,
  author = {P. Lewis and others},
  title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {9459--9474},
  year = {2020}
}

@inproceedings{karpukhin2020dense,
  author = {V. Karpukhin and others},
  title = {Dense Passage Retrieval for Open-Domain Question Answering},
  booktitle = {Proceedings of EMNLP},
  pages = {6769--6781},
  year = {2020}
}

@article{pan2024large,
  author = {J. Pan and S. Razniewski and J. Z. Pan and G. Weikum},
  title = {Large Language Models and Knowledge Graphs: Opportunities and Challenges},
  journal = {Trans. Graph Data Knowledge},
  volume = {1},
  number = {1},
  pages = {1--38},
  year = {2024}
}

@article{hogan2021knowledge,
  author = {A. Hogan and others},
  title = {Knowledge Graphs},
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {4},
  pages = {1--37},
  year = {2021}
}

@inproceedings{yao2023react,
  author = {S. Yao and others},
  title = {ReAct: Synergizing Reasoning and Acting in Language Models},
  booktitle = {Proceedings of ICLR},
  year = {2023}
}

@inproceedings{carlini2021extracting,
  author = {N. Carlini and others},
  title = {Extracting Training Data from Large Language Models},
  booktitle = {Proceedings of USENIX Security},
  pages = {2633--2650},
  year = {2021}
}

@inproceedings{izacard2021leveraging,
  author = {G. Izacard and E. Grave},
  title = {Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering},
  booktitle = {Proceedings of EACL},
  pages = {874--880},
  year = {2021}
}

@inproceedings{borgeaud2022improving,
  author = {S. Borgeaud and others},
  title = {Improving Language Models by Retrieving from Trillions of Tokens},
  booktitle = {Proceedings of ICML},
  pages = {2206--2240},
  year = {2022}
}

@misc{chase2022langchain,
  author = {H. Chase},
  title = {LangChain: Building Applications with LLMs through Composability},
  howpublished = {GitHub Repository},
  year = {2022}
}

@article{chakraborty2023survey,
  author = {S. Chakraborty and others},
  title = {Survey on Knowledge Graph-based Question Answering Systems},
  journal = {IEEE Access},
  volume = {11},
  pages = {61329--61344},
  year = {2023}
}

@inproceedings{yasunaga2021qa,
  author = {M. Yasunaga and others},
  title = {QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering},
  booktitle = {Proceedings of NAACL},
  pages = {535--546},
  year = {2021}
}

@article{pan2024unifying,
  author = {S. Pan and others},
  title = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
  journal = {IEEE Trans. Knowl. Data Eng.},
  volume = {36},
  number = {7},
  pages = {3580--3599},
  year = {2024}
}

@inproceedings{sun2024think,
  author = {J. Sun and others},
  title = {Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph},
  booktitle = {Proceedings of ICLR},
  year = {2024}
}

@techreport{microsoft2024graphrag,
  author = {{Microsoft Research}},
  title = {GraphRAG: A Modular Graph-Based RAG System},
  institution = {Microsoft Research},
  year = {2024}
}

@misc{edge2024local,
  author = {D. Edge and others},
  title = {From Local to Global: A Graph RAG Approach to Query-Focused Summarization},
  howpublished = {arXiv:2404.16130},
  year = {2024}
}

@article{ram2023context,
  author = {O. Ram and others},
  title = {In-Context Retrieval-Augmented Language Models},
  journal = {Trans. Assoc. Comput. Linguist.},
  volume = {11},
  pages = {1316--1331},
  year = {2023}
}

@inproceedings{muennighoff2023mteb,
  author = {N. Muennighoff and others},
  title = {MTEB: Massive Text Embedding Benchmark},
  booktitle = {Proceedings of EACL},
  pages = {2014--2037},
  year = {2023}
}

@inproceedings{mudgal2018deep,
  author = {S. Mudgal and others},
  title = {Deep Learning for Entity Matching: A Design Space Exploration},
  booktitle = {Proceedings of SIGMOD},
  pages = {19--34},
  year = {2018}
}

@inproceedings{yang2018hotpotqa,
  author = {Z. Yang and others},
  title = {HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  booktitle = {Proceedings of EMNLP},
  pages = {2369--2380},
  year = {2018}
}

@inproceedings{ho2020constructing,
  author = {X. Ho and others},
  title = {Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps},
  booktitle = {Proceedings of COLING},
  pages = {6609--6625},
  year = {2020}
}

@inproceedings{wei2022chain,
  author = {J. Wei and others},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  booktitle = {Advances in NeurIPS},
  volume = {35},
  pages = {24824--24837},
  year = {2022}
}

@article{liu2024lost,
  author = {Y. Liu and others},
  title = {Lost in the Middle: How Language Models Use Long Contexts},
  journal = {Trans. Assoc. Comput. Linguist.},
  volume = {12},
  pages = {157--173},
  year = {2024}
}

@article{trivedi2022musique,
  author = {P. Trivedi and others},
  title = {MuSiQue: Multihop Questions via Single-hop Question Composition},
  journal = {Trans. Assoc. Comput. Linguist.},
  volume = {10},
  pages = {539--554},
  year = {2022}
}

@article{landis1977measurement,
  author = {J. R. Landis and G. G. Koch},
  title = {The Measurement of Observer Agreement for Categorical Data},
  journal = {Biometrics},
  volume = {33},
  number = {1},
  pages = {159--174},
  year = {1977}
}

@inproceedings{vaswani2017attention,
  author = {A. Vaswani and others},
  title = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {30},
  pages = {5998--6008},
  year = {2017}
}

@inproceedings{devlin2019bert,
  author = {J. Devlin and others},
  title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of NAACL-HLT},
  pages = {4171--4186},
  year = {2019}
}
